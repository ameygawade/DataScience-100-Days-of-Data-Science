{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e24c73e",
   "metadata": {},
   "source": [
    "# Day 33: Clustering Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a2ecf",
   "metadata": {},
   "source": [
    "Welcome to Day 33! Unlike supervised learning, where you have a clear target variable to measure your model against, evaluating unsupervised clustering models is more nuanced. Since there's no \"correct\" answer, we use metrics that assess the quality and compactness of the clusters themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8ce94",
   "metadata": {},
   "source": [
    "## Topics Covered:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c692a",
   "metadata": {},
   "source": [
    "- The Challenge of Evaluating Unsupervised Models\n",
    "\n",
    "- Common Clustering Metrics\n",
    "    - Intertia\n",
    "\n",
    "    - Silhouette Score\n",
    "\n",
    "    - Davies-Bouldin Index\n",
    "\n",
    "    - Calinski-Harabasz Index\n",
    "\n",
    "- How to Interpret These Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2cb6ea",
   "metadata": {},
   "source": [
    "## The Challenge of Unsupervised Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77036434",
   "metadata": {},
   "source": [
    "In supervised learning, we have an answer key (the labels). We can easily calculate how many predictions were correct using metrics like accuracy or an F1-Score. \n",
    "\n",
    "In unsupervised learning, however, we don't have labels. The model is creating its own structure, and we need to find a way to measure how \"good\" that structure is without an answer key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e3f47",
   "metadata": {},
   "source": [
    "So, we use **internal evaluation metrics** to assess the compactness and separation of clusters:\n",
    "- **Compactness**: Points within a cluster should be close to each other.\n",
    "- **Separation**: Clusters should be well-separated from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7249185b",
   "metadata": {},
   "source": [
    "## Internal Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c295e4b",
   "metadata": {},
   "source": [
    "### Inertia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511c431f",
   "metadata": {},
   "source": [
    "Inertia is sum of squared distances of samples to their closest cluster center. It measures how compact the clusters are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ffedb",
   "metadata": {},
   "source": [
    "### Silhouette Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b21ed",
   "metadata": {},
   "source": [
    "Measures **how similar a point is to its own cluster vs. other clusters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebc609",
   "metadata": {},
   "source": [
    "\n",
    "- Ranges from **-1 to 1**:\n",
    "  - +1 → well-clustered\n",
    "  - 0 → on the boundary\n",
    "  - -1 → wrongly clustered\n",
    "\n",
    "#### Formula:\n",
    "\n",
    "For a point \\( i \\):\n",
    "\n",
    "- a(i): average distance to points in the **same** cluster  \n",
    "- b(i): lowest average distance to points in **another** cluster  \n",
    "\n",
    "$$ Silhouette(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84891e",
   "metadata": {},
   "source": [
    "### Davies-Bouldin Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf8b95d",
   "metadata": {},
   "source": [
    "The Davies-Bouldin Index measures the average similarity between each cluster and its most similar cluster. Similarity is a ratio of within-cluster distance to between-cluster distance. A lower Davies-Bouldin score indicates a better clustering. A perfect score is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445e4b0",
   "metadata": {},
   "source": [
    "$$DB = \\frac{1}{k} \\sum_{i=1}^{k} \\max_{j \\neq i} \\left(\\frac{\\sigma_i + \\sigma_j}{d(c_i, c_j)}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b71a3f",
   "metadata": {},
   "source": [
    "### Calinski-Harabasz Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ba24c",
   "metadata": {},
   "source": [
    "Also known as the Variance Ratio Criterion, this index is a ratio of the between-cluster variance to the within-cluster variance. A higher score means the clusters are better defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb8253",
   "metadata": {},
   "source": [
    "$$CH = \\frac{SS_B / (k-1)}{SS_W / (N-k)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e285eb",
   "metadata": {},
   "source": [
    "## External Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a63eb",
   "metadata": {},
   "source": [
    "### Adjusted Rand Index (ARI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071dec50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "888e4d92",
   "metadata": {},
   "source": [
    "### When to Use Which Clustering Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe5903",
   "metadata": {},
   "source": [
    "#### When you DO NOT have Ground Truth Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5675f876",
   "metadata": {},
   "source": [
    "| Metric | When to Use It | Analogy to Explain |\n",
    "| :--- | :--- | :--- |\n",
    "| **Inertia** | To determine the **optimal number of clusters (k)**. Use it with the Elbow Method. The goal is to find the \"k\" where adding more clusters no longer significantly decreases the inertia. | **The Team Huddle:** Imagine a sports team huddling. Inertia measures how close each player is to the center of their team's huddle. You want them close, but a huddle of one player isn't a team. The elbow point is the sweet spot where the teams are as compact as possible without being too fragmented. |\n",
    "| **Silhouette Score** | To compare the performance of different clustering algorithms or a different number of clusters. A higher score is better. It balances **compactness** and **separation**. | **The Socialite's Scorecard:** A socialite wants to know if they're in the right friend group. Their score is high if they are very close to their own friends and very far from other groups. A score of 1 is ideal, 0 means they're on the border, and -1 means they're in the wrong group. |\n",
    "| **Davies-Bouldin Index** | To compare different clustering results. A **lower score is better**, with 0 being the perfect score. It measures the ratio of within-cluster distance to between-cluster distance. | **The Bubble Bath:** The index measures how close a bubble is to its closest neighbor. A low score means the bubbles are tight and well-defined (compact) and the bubbles themselves are far apart (well-separated). |\n",
    "| **Calinski-Harabasz Index** | To compare the quality of different clustering results. A **higher score is better**. It measures the ratio of between-cluster variance to within-cluster variance. | **The Bandstand:** This index measures how much better organized the bands are when they are on their own stage versus when they are all jumbled together. A high score means the groups are distinct and well-separated. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f3a08",
   "metadata": {},
   "source": [
    "When you DO have Ground Truth Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfad4e1",
   "metadata": {},
   "source": [
    "| Metric | When to Use It | Analogy to Explain |\n",
    "| :--- | :--- | :--- |\n",
    "| **Adjusted Rand Index (ARI)** | To see how well your clustering algorithm **\"rediscovered\"** the true labels in your data. It's the most robust metric for this purpose. The score ranges from -1 to 1, with 1 being a perfect match. | **The Answer Key:** You've just sorted a mixed box of sports balls. The ARI is like having a teacher's answer key that tells you which balls are which. The score tells you how perfectly your sorting matches the key. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8687e76",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
