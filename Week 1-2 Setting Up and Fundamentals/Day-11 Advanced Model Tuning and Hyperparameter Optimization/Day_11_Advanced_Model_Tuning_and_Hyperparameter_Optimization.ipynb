{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed4ad761",
   "metadata": {},
   "source": [
    "# Day 11: Advanced Model Tuning and Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb83fec",
   "metadata": {},
   "source": [
    "Today, we will take a step beyond basic model building and learn how to improve model performance using hyperparameter tuning and cross-validation techniques. These practices help us build more robust models that generalize better on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82420f2f",
   "metadata": {},
   "source": [
    "## Topic covered:\n",
    "- Introduction to Model Tuning\n",
    "\n",
    "- Understanding Hyperparameters vs Parameters\n",
    "\n",
    "- Grid Search and Random Search\n",
    "\n",
    "- Cross-Validation Techniques\n",
    "\n",
    "- Applying Cross-Validation with Regularized Models (Ridge, Lasso, ElasticNet)\n",
    "\n",
    "- Evaluation Metrics Recap: MSE, Accuracy, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d7837",
   "metadata": {},
   "source": [
    "## 1. Introduction to Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05577580",
   "metadata": {},
   "source": [
    "Most machine learning models have hyperparameters—these are settings that you specify before training the model (e.g., alpha in Ridge or Lasso Regression).\n",
    "\n",
    "Tuning these hyperparameters helps:\n",
    "\n",
    "    - Improve model accuracy\n",
    "\n",
    "    - Prevent overfitting\n",
    "\n",
    "    - Optimize performance on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70303f9f",
   "metadata": {},
   "source": [
    "## 2. Parameters vs Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53062da",
   "metadata": {},
   "source": [
    "| Term                | Definition                                  | Example                                        |\n",
    "| ------------------- | ------------------------------------------- | ---------------------------------------------- |\n",
    "| **Model Parameter** | Learned from data during training           | Coefficients (`β`) in linear regression        |\n",
    "| **Hyperparameter**  | Set before training; governs model behavior | `alpha` in Ridge, `max_depth` in Decision Tree |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86259ce3",
   "metadata": {},
   "source": [
    "## 3. Grid Search vs Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2edcc95",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69530964",
   "metadata": {},
   "source": [
    "Tries every combination of specified hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008c6b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (house sizes and prices)\n",
    "X = np.array([1000, 1500, 2000, 2500, 3000]).reshape(-1, 1)\n",
    "y = np.array([200000, 300000, 400000, 500000, 600000])\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Example: Tune alpha in Ridge Regression\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(Ridge(), param_grid, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best alpha:\", grid.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e166be3c",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302d291",
   "metadata": {},
   "source": [
    "Randomly tries combinations from a parameter distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23586648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'alpha': np.float64(2.409504255788265)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1283: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "c:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "param_dist = {'alpha': uniform(0.01, 10)}\n",
    "random_search = RandomizedSearchCV(Ridge(), param_distributions=param_dist, n_iter=10, cv=4)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Best alpha:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96f3e6",
   "metadata": {},
   "source": [
    "## 4. Cross-Validation(CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbf0950",
   "metadata": {},
   "source": [
    "Cross-validation helps evaluate the model more reliably by splitting data into several folds:\n",
    "\n",
    "- k-Fold CV: Splits data into k parts and rotates training/testing\n",
    "\n",
    "- Leave-One-Out CV: One data point is used as test, rest as train (very slow)\n",
    "\n",
    "- Stratified K-Fold: Maintains class distribution (used in classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b070497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average CV MSE: 0.01730609565500119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(Ridge(alpha=1), X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Average CV MSE:\", -scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06844ae6",
   "metadata": {},
   "source": [
    "## 5. Applying CV and Tuning on Ridge & Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99095b0d",
   "metadata": {},
   "source": [
    "Ridge Example with Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408a9092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'alpha': 0.01}\n",
      "Best MSE: 1.006841674867602e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge = Ridge()\n",
    "params = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(ridge, params, cv=4, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha:\", grid_search.best_params_)\n",
    "print(\"Best MSE:\", -grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d0a59",
   "metadata": {},
   "source": [
    "## 6. Evaluation Metrics Recap (for Tuning):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140398b",
   "metadata": {},
   "source": [
    "| Metric     | Use Case                  | Higher or Lower is Better |\n",
    "| ---------- | ------------------------- | ------------------------- |\n",
    "| MSE / RMSE | Regression                | Lower                     |\n",
    "| R² Score   | Regression                | Higher                    |\n",
    "| Accuracy   | Classification            | Higher                    |\n",
    "| F1 Score   | Imbalanced classification | Higher                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea0f37",
   "metadata": {},
   "source": [
    "Use the appropriate scoring metric when doing GridSearchCV (e.g., scoring='accuracy' for classification, scoring='neg_mean_squared_error' for regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cfce59",
   "metadata": {},
   "source": [
    "## Summary of Day 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca288d",
   "metadata": {},
   "source": [
    "Today, we explored techniques to fine-tune our machine learning models using:\n",
    "\n",
    "    - Grid Search and Random Search to find optimal hyperparameters\n",
    "\n",
    "    - Cross-Validation to assess model robustness and reduce overfitting\n",
    "\n",
    "    - Practical application on Ridge and Lasso regressions using MSE as an evaluation metric\n",
    "\n",
    "By using these techniques, you can ensure your models are not only accurate but also generalize well to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bd506",
   "metadata": {},
   "source": [
    "## What's Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36b30fa",
   "metadata": {},
   "source": [
    "On Day 12, we will dive into Decision Trees for both regression and classification tasks. You’ll learn:\n",
    "\n",
    "- How trees split data\n",
    "\n",
    "- Metrics like Gini Impurity and Entropy\n",
    "\n",
    "- How to avoid overfitting with pruning and depth control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66d075",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
