{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4b5ccb",
   "metadata": {},
   "source": [
    "# Day-59: Forward and Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c6e68",
   "metadata": {},
   "source": [
    "Today,we’re diving into the heart of how neural networks actually learn — Forward Propagation and Backpropagation.\n",
    "\n",
    "Think of this as the learning cycle of a neural network — how it makes a prediction, realizes how wrong it was, and then corrects itself step by step until it becomes a smart model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18134cc3",
   "metadata": {},
   "source": [
    "## Topic Covered:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e3dce",
   "metadata": {},
   "source": [
    "- Forward Propagation\n",
    "\n",
    "- Loss Function\n",
    "\n",
    "- Gradient Descent\n",
    "\n",
    "- Backpropagation\n",
    "\n",
    "- Weight Update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f4616",
   "metadata": {},
   "source": [
    "## Forward Propagation (The Guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dd7040",
   "metadata": {},
   "source": [
    "**Forward Propagation** is the process of feeding the input data (  $ \\vec x $\n",
    " ) through the network, layer by layer, to compute the final output prediction ( $\\^y$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29049ab",
   "metadata": {},
   "source": [
    "**Process**:\n",
    "\n",
    "1. Input: Features ( $\\vec x $) are fed into the first layer.\n",
    "\n",
    "2. Weighted Sum: Each neuron calculates the linear combination: $ z=( \\vec x ⋅ \\vec w)+b $.\n",
    "\n",
    "3. Activation: The output $ z $ is passed through an Activation Function (like $ReLU$) to introduce non-linearity: $a=ReLU(z)$.\n",
    "\n",
    "4. Repeat: This activated output (a) becomes the input for the next layer.\n",
    "\n",
    "5. Prediction ($\\hat y$ ): The final output layer produces the network's prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db3e23",
   "metadata": {},
   "source": [
    "- `analogy`: \n",
    "    - Imagine you’re a teacher grading a student’s math answer. The student (neural network) takes the question (input), does some calculations (weighted sum + activation), and gives an answer (output).\n",
    "\n",
    "    - Forward propagation is just the student solving the problem — passing inputs through layers and generating an output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a5f72",
   "metadata": {},
   "source": [
    "## Loss Functions (Measuring the Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0485168",
   "metadata": {},
   "source": [
    "Once the network makes a prediction $( \\hat y)$, we need a metric to measure how wrong it was compared to the true label $(y)$. This metric is the Loss Function (or Cost Function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de333259",
   "metadata": {},
   "source": [
    "Basically, It's a function that quantifies the difference between the network's predicted output and the actual target value. A lower loss means a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6436f1",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a949e",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE) (For Regression)\n",
    "$$ \\text{Loss} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67968808",
   "metadata": {},
   "source": [
    "### Categorical Cross-Entropy (For Classification - Most Common)\n",
    "$$ \\text{Loss} = - \\sum_{i} y_i \\log(\\hat{y}_i) $$\n",
    "This penalizes the model heavily when it predicts a low probability for the correct class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59662229",
   "metadata": {},
   "source": [
    "## Gradient Descent (The Optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e365369",
   "metadata": {},
   "source": [
    "The Gradient tells us the direction of the steepest increase in loss. To minimize the loss, we must move in the opposite direction. This is Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6b242",
   "metadata": {},
   "source": [
    "- `Analogy`: Walking Down a Hill\n",
    "    - Imagine you are blindfolded on a foggy hill (the loss surface) and want to find the lowest point (minimum loss). You can't see the bottom, but you can feel the slope (the gradient). You take small, careful steps in the direction of the steepest descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d6b8ae",
   "metadata": {},
   "source": [
    "## Backpropagation (The Correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eeff17",
   "metadata": {},
   "source": [
    "This is the core learning mechanism. It uses the calculated Loss to figure out exactly how much each weight $(w)$ and bias $(b)$ contributed to that error, and then adjusts them slightly to reduce the error next time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61f9d8",
   "metadata": {},
   "source": [
    "The Chain Rule: Backpropagation relies entirely on the Chain Rule from calculus to distribute the total error backward through all the layers. It calculates the gradient (slope) of the loss function with respect to every single weight in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cbf30",
   "metadata": {},
   "source": [
    "### The Chain Rule:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4b383",
   "metadata": {},
   "source": [
    "Backpropagation relies entirely on the Chain Rule from calculus to distribute the total error backward through all the layers. It calculates the gradient (slope) of the loss function with respect to every single weight in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b098899",
   "metadata": {},
   "source": [
    "### The Update Rule (Weight Updates):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3468f",
   "metadata": {},
   "source": [
    "\n",
    "We update every weight ( \n",
    "w\n",
    " ) in the network using this fundamental formula:\n",
    "\n",
    "$$ w_{\\text{new}} = w_{\\text{old}} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial w_{\\text{old}}} $$\n",
    "\n",
    "∂w \n",
    "old\n",
    "​\n",
    " \n",
    "∂Loss\n",
    "​\n",
    " : The Gradient calculated by Backpropagation.\n",
    "\n",
    "η (eta): The Learning Rate (a hyperparameter). This controls the size of the steps you take down the hill.\n",
    "\n",
    "If η is too large, you might overshoot the minimum (the optimal weights).\n",
    "\n",
    "If η is too small, training will take too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0dcc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gradient Descent Simulation (Minimizing f(x) = x^2) ---\n",
      "Starting Point (x): 4.0\n",
      "Learning Rate (eta): 0.1\n",
      "Minimum is at x = 0, Loss = 0.\n",
      "\n",
      "--- Iteration History ---\n",
      "|   Iteration |   Current x |   Gradient |   Current Loss |\n",
      "|-------------|-------------|------------|----------------|\n",
      "|           1 |     3.2     |    8       |       10.24    |\n",
      "|           2 |     2.56    |    6.4     |        6.5536  |\n",
      "|           3 |     2.048   |    5.12    |        4.1943  |\n",
      "|           4 |     1.6384  |    4.096   |        2.68435 |\n",
      "|           5 |     1.31072 |    3.2768  |        1.71799 |\n",
      "|           6 |     1.04858 |    2.62144 |        1.09951 |\n",
      "|           7 |     0.83886 |    2.09715 |        0.70369 |\n",
      "|           8 |     0.67109 |    1.67772 |        0.45036 |\n",
      "|           9 |     0.53687 |    1.34218 |        0.28823 |\n",
      "|          10 |     0.4295  |    1.07374 |        0.18447 |\n",
      "\n",
      "Final x value after 10 iterations: 0.4295\n",
      "Final Loss: 0.18447\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# --- 1. Define the Loss Function and its Derivative (Gradient) ---\n",
    "\n",
    "def loss_function(x):\n",
    "    \"\"\"The function we want to minimize: f(x) = x^2.\"\"\"\n",
    "    return x**2\n",
    "\n",
    "def gradient(x):\n",
    "    \"\"\"The derivative (slope) of the loss function: f'(x) = 2x.\"\"\"\n",
    "    return 2 * x\n",
    "\n",
    "# --- 2. Gradient Descent Algorithm ---\n",
    "\n",
    "def gradient_descent(starting_point, learning_rate, n_iterations):\n",
    "    \"\"\"\n",
    "    Applies the gradient descent algorithm to find the minimum of the loss function.\n",
    "    In a NN, x would be the weights (w).\n",
    "    \"\"\"\n",
    "    current_x = starting_point\n",
    "    history = []\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        # Calculate the gradient (slope) at the current point\n",
    "        grad = gradient(current_x)\n",
    "\n",
    "        # Update Rule: Move opposite to the slope\n",
    "        # x_new = x_old - learning_rate * gradient\n",
    "        current_x = current_x - learning_rate * grad\n",
    "\n",
    "        # Record the state\n",
    "        history.append([\n",
    "            i + 1, \n",
    "            np.round(current_x, 5), \n",
    "            np.round(grad, 5), \n",
    "            np.round(loss_function(current_x), 5)\n",
    "        ])\n",
    "\n",
    "    return current_x, history\n",
    "\n",
    "# --- 3. Run the Simulation ---\n",
    "# Parameters\n",
    "starting_point = 4.0      # Start high on the parabola\n",
    "learning_rate = 0.1       # How big are our steps?\n",
    "n_iterations = 10         # How many steps to take?\n",
    "\n",
    "# Run the descent\n",
    "final_x, descent_history = gradient_descent(starting_point, learning_rate, n_iterations)\n",
    "\n",
    "# Display Results\n",
    "print(\"--- Gradient Descent Simulation (Minimizing f(x) = x^2) ---\")\n",
    "print(f\"Starting Point (x): {starting_point}\")\n",
    "print(f\"Learning Rate (eta): {learning_rate}\")\n",
    "print(f\"Minimum is at x = 0, Loss = 0.\")\n",
    "\n",
    "print(\"\\n--- Iteration History ---\")\n",
    "print(tabulate(descent_history, \n",
    "               headers=[\"Iteration\", \"Current x\", \"Gradient\", \"Current Loss\"], \n",
    "               tablefmt=\"github\"))\n",
    "\n",
    "print(f\"\\nFinal x value after {n_iterations} iterations: {np.round(final_x, 5)}\")\n",
    "print(f\"Final Loss: {np.round(loss_function(final_x), 5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0159d670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2521\n",
      "Epoch 2000, Loss: 0.2467\n",
      "Epoch 4000, Loss: 0.1920\n",
      "Epoch 6000, Loss: 0.1324\n",
      "Epoch 8000, Loss: 0.0969\n",
      "Final Output:\n",
      " [[0.20369158]\n",
      " [0.73603066]\n",
      " [0.73604444]\n",
      " [0.34370702]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training data\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])  # Inputs\n",
    "y = np.array([[0], [1], [1], [0]])          # XOR Output\n",
    "\n",
    "# Initialize weights and learning rate\n",
    "np.random.seed(42)\n",
    "weights_input_hidden = np.random.rand(2, 2)\n",
    "weights_hidden_output = np.random.rand(2, 1)\n",
    "lr = 0.1\n",
    "\n",
    "for epoch in range(10000):\n",
    "    # Forward propagation\n",
    "    hidden_input = np.dot(X, weights_input_hidden)\n",
    "    hidden_output = sigmoid(hidden_input)\n",
    "\n",
    "    final_input = np.dot(hidden_output, weights_hidden_output)\n",
    "    final_output = sigmoid(final_input)\n",
    "\n",
    "    # Loss calculation (Mean Squared Error)\n",
    "    loss = np.mean((y - final_output) ** 2)\n",
    "\n",
    "    # Backpropagation\n",
    "    d_loss_output = (y - final_output) * sigmoid_derivative(final_output)\n",
    "    d_loss_hidden = d_loss_output.dot(weights_hidden_output.T) * sigmoid_derivative(hidden_output)\n",
    "\n",
    "    # Weight updates\n",
    "    weights_hidden_output += hidden_output.T.dot(d_loss_output) * lr\n",
    "    weights_input_hidden += X.T.dot(d_loss_hidden) * lr\n",
    "\n",
    "    if epoch % 2000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"Final Output:\\n\", final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4539418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
