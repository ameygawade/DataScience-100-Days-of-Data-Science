{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cae202",
   "metadata": {},
   "source": [
    "# Day 25: Gradient Boosting & XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4813cc83",
   "metadata": {},
   "source": [
    "We're on Day 25, and today we're tackling one of the most powerful and widely-used machine learning algorithms: Gradient Boosting and its star player, XGBoost. If you've ever wanted to win a Kaggle competition, you've probably heard of these. They're like the superheroes of predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0c4de",
   "metadata": {},
   "source": [
    "## Topics Covered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb75b77",
   "metadata": {},
   "source": [
    "- Boosting theory\n",
    "\n",
    "- Comparison with bagging\n",
    "\n",
    "- Learning rate\n",
    "\n",
    "- Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c70cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
