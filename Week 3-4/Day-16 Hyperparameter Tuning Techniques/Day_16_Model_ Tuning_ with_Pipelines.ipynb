{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c731e5cd",
   "metadata": {},
   "source": [
    "# Day-16 Model Tuning with Pipelines & Practical Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c0aef",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is a critical step in building a high-performing machine learning model. Today, we will explore two popular techniques:\n",
    "\n",
    "- Grid Search – exhaustive and systematic\n",
    "\n",
    "- Random Search – randomized and efficient\n",
    "\n",
    "- We will also implement both techniques using scikit-learn and understand when to use which."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63cc394",
   "metadata": {},
   "source": [
    "## Topics Covered\n",
    "\n",
    "- What is pipeline?\n",
    "\n",
    "- Why to Use a Pipeline?\n",
    "\n",
    "- Benefits of Using a Pipeline\n",
    "\n",
    "- Grid Search (GridSearchCV) [Revision]\n",
    "\n",
    "- Random Search (RandomizedSearchCV) [Revision]\n",
    "\n",
    "- When to Use Grid vs Random Search? \n",
    "\n",
    "- Hands-on Examples\n",
    "\n",
    "- Summary\n",
    "\n",
    "- Reference Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9910e",
   "metadata": {},
   "source": [
    "## What is a Pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f40d5",
   "metadata": {},
   "source": [
    "A pipeline in scikit-learn is a tool that chains multiple preprocessing steps(like sciling or encoding) abd a model into single object.\n",
    "\n",
    "It ensures that everystep in the workflow(preprocessing → training → prediction)is applied in the correct sequence, every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b98d9d",
   "metadata": {},
   "source": [
    "## Why Use a Pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75b8f7",
   "metadata": {},
   "source": [
    "In a real-world data science workflow, your model is just one part of the pipeline. You often need to:\n",
    "\n",
    "- Preprocess data (e.g., scale, encode)\n",
    "\n",
    "- Train/test split\n",
    "\n",
    "- Train models\n",
    "\n",
    "- Tune hyperparameters\n",
    "\n",
    "Manually managing this sequence can lead to data leakage, messy code, or inconsistent transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8c5c5",
   "metadata": {},
   "source": [
    "## Benefits of Using a Pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72680a",
   "metadata": {},
   "source": [
    "- Ensures consistent preprocessing during cross-validation\n",
    "\n",
    "- Reduces risk of data leakage\n",
    "\n",
    "- Makes your code modular and cleaner\n",
    "\n",
    "- Compatible with GridSearchCV and RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c34e9",
   "metadata": {},
   "source": [
    "## Example of simple Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27919b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe2d79",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a36ff9",
   "metadata": {},
   "source": [
    "## Revising Gridsearch CV from Day 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc58e53",
   "metadata": {},
   "source": [
    "### Key Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6add72",
   "metadata": {},
   "source": [
    "- Performs exhaustive search over specified hyperparameter values.\n",
    "\n",
    "- Works well for smaller search spaces.\n",
    "\n",
    "- Slower than RandomizedSearchCV when many combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c011f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m param_grid = {\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mridge__alpha\u001b[39m\u001b[33m'\u001b[39m: [\u001b[32m0.1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m100\u001b[39m]\n\u001b[32m      5\u001b[39m }\n\u001b[32m      7\u001b[39m grid = GridSearchCV(pipe, param_grid, cv=\u001b[32m5\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mneg_mean_squared_error\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m grid.fit(\u001b[43mX_train\u001b[49m, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6acb880",
   "metadata": {},
   "source": [
    "## Revising RandomizedSearchCV from Day 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80710c",
   "metadata": {},
   "source": [
    "### Key Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0b5ef",
   "metadata": {},
   "source": [
    "- Randomly samples from a parameter distribution.\n",
    "\n",
    "- Useful when you have a large or continuous search space.\n",
    "\n",
    "- Faster alternative to GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68b87cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m param_dist = {\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mridge__alpha\u001b[39m\u001b[33m'\u001b[39m: uniform(loc=\u001b[32m0.01\u001b[39m, scale=\u001b[32m10\u001b[39m)\n\u001b[32m      6\u001b[39m }\n\u001b[32m      8\u001b[39m random_search = RandomizedSearchCV(pipe, param_distributions=param_dist, n_iter=\u001b[32m10\u001b[39m, cv=\u001b[32m5\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mneg_mean_squared_error\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m random_search.fit(\u001b[43mX_train\u001b[49m, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "param_dist = {\n",
    "    'ridge__alpha': uniform(loc=0.01, scale=10)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error')\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c92d05",
   "metadata": {},
   "source": [
    "## Example of use of pipeline in regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba2774d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: {'lasso__alpha': 0.01}\n",
      "Best score (MSE): 0.6077113518445894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load data\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lasso', Lasso())\n",
    "])\n",
    "\n",
    "# GridSearch\n",
    "param_grid = {\n",
    "    'lasso__alpha': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha:\", grid.best_params_)\n",
    "print(\"Best score (MSE):\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ec706",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f97987d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Confusion Matrix:\n",
      " [[0 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute  import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'age': [25, 40, 35, 23],\n",
    "    'salary': [50000, 80000, 65000, 40000],\n",
    "    'gender': ['Male', 'Female', 'Female', 'Male'],\n",
    "    'region': ['North', 'South', 'East', 'West'],\n",
    "    'churn': [0, 1, 0, 1]  # Target: 0 = No Churn, 1 = Churn\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   \n",
    "\n",
    "# define preprocessing for numerical and categorical features\n",
    "numerical_features = ['age', 'salary']\n",
    "categorical_features = ['gender', 'region']\n",
    "\n",
    "# numerical pipeline\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# categorical pipeline\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# combine pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# final pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# train the pipeline\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "#evaluate\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679c3af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (1.7.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from scikit-learn) (2.3.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.2-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.3 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.3 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.3 MB 15.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 15.8 MB/s eta 0:00:00\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn pandas scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185e042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
