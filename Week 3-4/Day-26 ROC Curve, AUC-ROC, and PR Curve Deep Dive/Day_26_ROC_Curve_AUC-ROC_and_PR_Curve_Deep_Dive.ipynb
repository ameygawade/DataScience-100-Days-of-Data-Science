{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0c76cc",
   "metadata": {},
   "source": [
    "# Day-26: ROC Curve, AUC-ROC, and PR Curve Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0c6bd",
   "metadata": {},
   "source": [
    "## Topics Covered:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0f535",
   "metadata": {},
   "source": [
    " \n",
    "- Model Evaluation Recap: Accuracy, F1, ROC-AUC, PR Curve\n",
    "- Comparing Models: Logistic Regression, Decision Tree, Naive Bayes, KNN\n",
    "- Visualization: ROC Curves, PR Curves\n",
    "- Dataset: Kaggle Retail Dataset (Sales/Customer churn-like setup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9c94b0",
   "metadata": {},
   "source": [
    "#### **1. Accuracy: The Deceptive Metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d897c4",
   "metadata": {},
   "source": [
    "As we learned on Day 14, **Accuracy** is the proportion of correct predictions. While intuitive, it can be highly misleading in datasets with a significant class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d67d3c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "**Example:** In our retail dataset, imagine 90% of reviews are positive. A simple model that always predicts \"positive\" would achieve 90% accuracy, yet it completely fails to identify any negative reviews. This is where other metrics become essential to get a true picture of performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1f36be",
   "metadata": {},
   "source": [
    "#### **2. ROC Curve and AUC-ROC: The Full Picture**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7fc485",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The **ROC Curve** plots the **True Positive Rate (TPR)** against the **False Positive Rate (FPR)** at different classification thresholds. This visualization shows a model's performance across its entire range of sensitivity and specificity. The **Area Under the Curve (AUC)** provides a single number summarizing this performance; an AUC of 1.0 is perfect, while 0.5 is no better than random guessing.\n",
    "\n",
    "- **TPR (Recall):** Out of all actual positives, what proportion did the model correctly identify?\n",
    "- **FPR:** Out of all actual negatives, what proportion did the model incorrectly identify as positive?\n",
    "\n",
    "By plotting the ROC curve, you can visually compare how well different models separate the two classes. A model with a curve that hugs the top-left corner is superior, as it achieves a high TPR with a low FPR. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee192a08",
   "metadata": {},
   "source": [
    "### ðŸ› ï¸ Use Case: Retail Product Sentiment Analysis\n",
    "\n",
    "Let's use a retail review dataset to classify customer sentiment as 'positive' or 'negative'. This is a common business use case, and the data is often imbalanced, with far more positive reviews than negative ones. We'll compare a Logistic Regression model with a k-Nearest Neighbors (k-NN) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf6f9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amey9\\documents\\github\\datascience-100-days-of-data-science\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn matplotlib scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e680e377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found. Please download from Kaggle or use a local path.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 5, n_samples_fit = 4, n_samples = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Predict probabilities and classes\u001b[39;00m\n\u001b[32m     50\u001b[39m log_reg_probs = log_reg_model.predict_proba(X_test_tfidf)[:, \u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m knn_probs = \u001b[43mknn_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_tfidf\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m     52\u001b[39m log_reg_preds = log_reg_model.predict(X_test_tfidf)\n\u001b[32m     53\u001b[39m knn_preds = knn_model.predict(X_test_tfidf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:371\u001b[39m, in \u001b[36mKNeighborsClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n\u001b[32m    369\u001b[39m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[32m    370\u001b[39m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     neigh_ind = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     neigh_dist = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amey9\\Documents\\GitHub\\DataScience-100-Days-of-Data-Science\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:854\u001b[39m, in \u001b[36mKNeighborsMixin.kneighbors\u001b[39m\u001b[34m(self, X, n_neighbors, return_distance)\u001b[39m\n\u001b[32m    852\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    853\u001b[39m         inequality_str = \u001b[33m\"\u001b[39m\u001b[33mn_neighbors <= n_samples_fit\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    855\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    856\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    857\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[32m    858\u001b[39m     )\n\u001b[32m    860\u001b[39m n_jobs = effective_n_jobs(\u001b[38;5;28mself\u001b[39m.n_jobs)\n\u001b[32m    861\u001b[39m chunked_results = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 5, n_samples_fit = 4, n_samples = 3"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset (replace with your specific dataset path)\n",
    "# We'll use a hypothetical retail review dataset for this example.\n",
    "try:\n",
    "    df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please download from Kaggle or use a local path.\")\n",
    "    # For demonstration, let's create a dummy DataFrame\n",
    "    data = {\n",
    "        'Review Text': ['Great product, love it!', 'Terrible quality, never again.', 'Fits well, very happy.', 'Slightly disappointed, but okay.', 'The worst I have ever bought.', 'Exactly what I wanted, perfect!', 'Awful, broke after one use.'],\n",
    "        'Rating': [5, 1, 4, 3, 1, 5, 2]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocessing: Create a binary target variable\n",
    "df['sentiment'] = df['Rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# Drop any rows with missing review text\n",
    "df.dropna(subset=['Review Text'], inplace=True)\n",
    "\n",
    "# Split the data\n",
    "X = df['Review Text']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Feature Engineering: Convert text to numerical features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "log_reg_model = LogisticRegression(random_state=42)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5) # We covered k-NN on Day 22\n",
    "\n",
    "# Train the models\n",
    "log_reg_model.fit(X_train_tfidf, y_train)\n",
    "knn_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict probabilities and classes\n",
    "log_reg_probs = log_reg_model.predict_proba(X_test_tfidf)[:, 1]\n",
    "knn_probs = knn_model.predict_proba(X_test_tfidf)[:, 1]\n",
    "log_reg_preds = log_reg_model.predict(X_test_tfidf)\n",
    "knn_preds = knn_model.predict(X_test_tfidf)\n",
    "\n",
    "# --- Performance Evaluation ---\n",
    "\n",
    "print(\"--- Model Accuracy ---\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, log_reg_preds):.4f}\")\n",
    "print(f\"k-NN Accuracy: {accuracy_score(y_test, knn_preds):.4f}\")\n",
    "\n",
    "# Classification Report (Precision, Recall, F1-score)\n",
    "print(\"\\n--- Logistic Regression Classification Report ---\")\n",
    "print(classification_report(y_test, log_reg_preds))\n",
    "\n",
    "print(\"\\n--- k-NN Classification Report ---\")\n",
    "print(classification_report(y_test, knn_preds))\n",
    "\n",
    "# ROC Curve & AUC\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, log_reg_probs)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, knn_probs)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, color='blue', lw=2, label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})')\n",
    "plt.plot(fpr_knn, tpr_knn, color='red', lw=2, label=f'k-NN (AUC = {roc_auc_knn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random Guessing')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_lr, recall_lr, _ = precision_recall_curve(y_test, log_reg_probs)\n",
    "precision_knn, recall_knn, _ = precision_recall_curve(y_test, knn_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_lr, precision_lr, color='blue', lw=2, label='Logistic Regression')\n",
    "plt.plot(recall_knn, precision_knn, color='red', lw=2, label='k-NN')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve Comparison')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf38be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
