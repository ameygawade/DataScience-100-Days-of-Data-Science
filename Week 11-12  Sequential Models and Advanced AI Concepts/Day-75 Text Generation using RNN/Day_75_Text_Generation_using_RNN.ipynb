{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f65e5eb6",
      "metadata": {
        "id": "f65e5eb6"
      },
      "source": [
        "# Day-75: Text Generation using RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47ad7f7",
      "metadata": {
        "id": "f47ad7f7"
      },
      "source": [
        "In the last few days, we explored RNNs, LSTMs, GRUs, and Bidirectional Networks, learning how these models understand sequential data like text or time series.\n",
        "\n",
        "Today, we’ll take it one step further — and build something creative:\n",
        "A Text Generator using RNNs!\n",
        "\n",
        "We’ll train an RNN on a children’s stories corpus, and then make it generate new story text word-by-word — just like how ChatGPT or any AI writer starts from a word and keeps predicting the next one."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c321e2",
      "metadata": {
        "id": "c4c321e2"
      },
      "source": [
        "## Topics Covered"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e550d7c",
      "metadata": {
        "id": "1e550d7c"
      },
      "source": [
        "- About the Dataset\n",
        "\n",
        "- Revisiting NLP Concepts We’ll Use\n",
        "\n",
        "- Preparing Data for RNN Text Generation\n",
        "\n",
        "- Building the RNN Model\n",
        "\n",
        "- Generating Text Word-by-Word\n",
        "\n",
        "- Evaluation & Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e6066bb",
      "metadata": {
        "id": "0e6066bb"
      },
      "source": [
        "## The Dataset: Children Stories Text Corpus (Kaggle)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228693a9",
      "metadata": {
        "id": "228693a9"
      },
      "source": [
        "Guys, for any project, the first step is always the data! Our dataset is a fantastic collection of children's stories. Why stories? Because they have a sequence and a context."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f6df8a",
      "metadata": {
        "id": "f6f6df8a"
      },
      "source": [
        "`Analogy`:\n",
        "- Think of this dataset as a massive library of bedtime stories.\n",
        "- When a kid reads a lot of stories, they learn the structure: \"Once upon a time...\" is often followed by a character introduction.\n",
        "- Our model is going to \"read\" this library and learn the grammar, the sentence structure, and the word-to-word dependencies to tell its own story."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d383ac",
      "metadata": {
        "id": "73d383ac"
      },
      "source": [
        "We’ll be using the Children Stories Text Corpus:https://www.kaggle.com/datasets/edenbd/children-stories-text-corpus/data from Kaggle.\n",
        "It contains hundreds of story texts written for kids — simple grammar, repetitive sentence structures, and rich vocabulary — perfect for language generation tasks!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef7b84d",
      "metadata": {
        "id": "8ef7b84d"
      },
      "source": [
        "This kind of dataset helps our RNN learn storytelling patterns like:\n",
        "\n",
        "- Sentence structure (subject → verb → object)\n",
        "\n",
        "- Repetitive story motifs (\"Once upon a time\", \"and then\", etc.)\n",
        "\n",
        "- Predictable transitions (\"The next day...\", \"Suddenly...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67128e2d",
      "metadata": {
        "id": "67128e2d"
      },
      "source": [
        "## Concepts from NLP we will use"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b4df8e8",
      "metadata": {
        "id": "5b4df8e8"
      },
      "source": [
        "We aren't starting from scratch! We'll leverage the power of foundational NLP concepts we covered previously."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad2ed04",
      "metadata": {
        "id": "3ad2ed04"
      },
      "source": [
        "| **NLP Concept**                        | **Day Covered**              | **How We Use It in Text Generation**                                                        | **Analogy**                                                                                                                  |\n",
        "| :------------------------------------- | :--------------------------- | :------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------- |\n",
        "| Tokenization                           | Day 50                       | We break the stories into words or characters, creating a vocabulary.                       | Breaking a long book into individual words to check the frequency of each word.                                              |\n",
        "| Lowercasing & Cleaning                 | Day 50                       | We normalize text to ensure uniformity — “Cat” and “cat” are treated the same.              | Making sure everyone wears the same uniform before a group photo.                                                            |\n",
        "| Stopwords                              | Day 50                       | Usually, we keep stopwords here as they help maintain the flow of sentences.                | Keeping connecting words like “and” or “but” to ensure the story makes sense.                                                |\n",
        "| Word Embeddings (e.g., Word2Vec/GloVe) | Day 52                       | We convert each token into a dense vector representation to capture semantic meaning.       | Giving each word a unique ID card that also contains information about what the word means and what words are similar to it. |\n",
        "| Sequence Data                          | General RNN Concept          | RNNs are designed to handle ordered data, so word order defines meaning in text generation. | A detective trying to solve a crime — the order of events is crucial to understanding the full story.                        |\n",
        "| Padding                                | (General Preprocessing)      | Ensures all input sequences are of the same length before feeding them into RNN.            | Making all sentences the same length by adding blank spaces at the start.                                                    |\n",
        "| One-hot / Categorical Encoding         | (Used before model training) | Converts the target (next word) into categorical vectors for training.                      | Giving each possible next word its own “slot” in the prediction list.                                                        |\n",
        "| Text Generation Loop                   | (Core to RNN Workflow)       | Repeatedly predicts the next word and appends it to the input sequence.                     | Like a storyteller who keeps adding one word at a time until the story ends.                                                 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0fcaa96",
      "metadata": {
        "id": "d0fcaa96"
      },
      "source": [
        "So yes — we’re reusing everything from Day 50–55!\n",
        "Only this time, we’re not classifying or clustering text — we’re generating new text."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba8ed19",
      "metadata": {
        "id": "dba8ed19"
      },
      "source": [
        "## Preparing Data for RNN Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8083ad1a",
      "metadata": {
        "id": "8083ad1a"
      },
      "source": [
        "### 1. Load the corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5d57d47f",
      "metadata": {
        "id": "5d57d47f",
        "outputId": "bf23aa01-7dbe-4e85-c2d5-26865c7dae0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'children-stories-text-corpus' dataset.\n",
            "Path to dataset files: /kaggle/input/children-stories-text-corpus\n",
            "/kaggle/input/children-stories-text-corpus/cleaned_merged_fairy_tales_without_eos.txt\n",
            "Number of characters: 20455694\n",
            "Sample preview (first 500 chars):\n",
            "\n",
            "The Happy Prince.\n",
            "HIGH above the city, on a tall column, stood the statue of the Happy Prince.  He was gilded all over with thin leaves of fine gold, for eyes he had two bright sapphires, and a large red ruby glowed on his sword-hilt.\n",
            "He was very much admired indeed.  “He is as beautiful as a weathercock,” remarked one of the Town Councillors who wished to gain a reputation for having artistic tastes; “only not quite so useful,” he added, fearing lest people should think him unpractical, which h\n",
            "\n",
            "After Cleanup:\n",
            "\n",
            "Number of characters: 22521845\n",
            "Sample preview (first 500 chars):\n",
            "\n",
            "the happy prince . <eos> high above the city , on a tall column , stood the statue of the happy prince . <eos> he was gilded all over with thin leaves of fine gold , for eyes he had two bright sapphires , and a large red ruby glowed on his sword - hilt . <eos> he was very much admired indeed . <eos> “ he is as beautiful as a weathercock , ” remarked one of the town councillors who wished to gain a reputation for having artistic tastes ; “ only not quite so useful , ” he added , fearing lest peop\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import kagglehub\n",
        "import re\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"edenbd/children-stories-text-corpus\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "DATA_FILE = \"cleaned_merged_fairy_tales_without_eos.txt\"\n",
        "CORPUS_PATH = f\"{path}/{DATA_FILE}\"\n",
        "print(CORPUS_PATH)\n",
        "assert os.path.exists(CORPUS_PATH), f'Could not find {CORPUS_PATH}.'\n",
        "\n",
        "with open(CORPUS_PATH, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print('Number of characters:', len(raw_text))\n",
        "print('Sample preview (first 500 chars):\\n')\n",
        "print(f'{raw_text[:500]}\\n')\n",
        "\n",
        "# tiny cleanup\n",
        "text = \" \".join(raw_text.split())\n",
        "text = text.lower()\n",
        "# inser <eos>(end of sentence) after sentence enders\n",
        "text = re.sub(r\"([.!?])\", r\" \\1 <eos>\", text)\n",
        "# space out other punctuation so they becode tokens\n",
        "text = re.sub(r'([,;:\\-—\"“”‘’()\\[\\]])', r' \\1 ', text)\n",
        "text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "print('After Cleanup:\\n')\n",
        "print('Number of characters:', len(text))\n",
        "print('Sample preview (first 500 chars):\\n')\n",
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69fdd695",
      "metadata": {
        "id": "69fdd695"
      },
      "source": [
        "### 2. Tokenize (word-level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a552ff19",
      "metadata": {
        "collapsed": true,
        "id": "a552ff19"
      },
      "outputs": [],
      "source": [
        "# ! pip install tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "67a49234",
      "metadata": {
        "id": "67a49234",
        "outputId": "fec9da03-21c9-4177-9ad2-dc1c9d0a26b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 10001\n",
            "Unique words (vocab):47449\n",
            "Number of tokens: 4806792\n",
            "Vocab used by model (input_dim):10001\n"
          ]
        }
      ],
      "source": [
        "# tonkenising words\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "NUM_WORDS = 10000\n",
        "OOV_TOKEN = \"<OOV>\"\n",
        "FILTER = ''\n",
        "\n",
        "tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=OOV_TOKEN, filters=FILTER)\n",
        "tokenizer.fit_on_texts([text])\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = (min(NUM_WORDS, len(word_index)) + 1)if NUM_WORDS else len(word_index) + 1\n",
        "tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "print(f'Vocabulary size: {vocab_size}')\n",
        "print(f\"Unique words (vocab):{len(word_index)}\")\n",
        "print(f'Number of tokens: {len(tokens)}')\n",
        "print(f\"Vocab used by model (input_dim):{vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Sequebce Building(sliding window -> next word)"
      ],
      "metadata": {
        "id": "BKSx8uBsFr1M"
      },
      "id": "BKSx8uBsFr1M"
    },
    {
      "cell_type": "code",
      "source": [
        "WIN = 60\n",
        "inputs, targets = [], []\n",
        "for i in range(WIN, len(tokens)):\n",
        "    inputs.append(tokens[i-WIN:i])\n",
        "    targets.append(tokens[i])\n",
        "\n",
        "X = np.array(inputs, dtype=np.int32)\n",
        "y = np.array(targets, dtype=np.int32)\n",
        "\n",
        "print(\"X:\", X.shape, \" y:\", y.shape)\n",
        "print(f\"Prview of X:\\n{X[:5]}\")\n",
        "print(f\"Prview of y:\\n{y[:5]}\")"
      ],
      "metadata": {
        "id": "bQCtzgvzFgWB",
        "outputId": "2d308e94-84a7-4b1c-9668-f5b9e534624a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bQCtzgvzFgWB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (4806732, 60)  y: (4806732,)\n",
            "Prview of X:\n",
            "[[   3  312  136    5    4  358  502    3  565    2   34    9  869 4745\n",
            "     2  231    3 3825    8    3  312  136    5    4   11   14 5015   39\n",
            "    98   26 1122  687    8  401  315    2   24  139   11   22  106  505\n",
            "     1    2    6    9  310  283 5173 5383   34   17  833   29 7979    5\n",
            "     4   11   14   67]\n",
            " [ 312  136    5    4  358  502    3  565    2   34    9  869 4745    2\n",
            "   231    3 3825    8    3  312  136    5    4   11   14 5015   39   98\n",
            "    26 1122  687    8  401  315    2   24  139   11   22  106  505    1\n",
            "     2    6    9  310  283 5173 5383   34   17  833   29 7979    5    4\n",
            "    11   14   67  114]\n",
            " [ 136    5    4  358  502    3  565    2   34    9  869 4745    2  231\n",
            "     3 3825    8    3  312  136    5    4   11   14 5015   39   98   26\n",
            "  1122  687    8  401  315    2   24  139   11   22  106  505    1    2\n",
            "     6    9  310  283 5173 5383   34   17  833   29 7979    5    4   11\n",
            "    14   67  114 3073]\n",
            " [   5    4  358  502    3  565    2   34    9  869 4745    2  231    3\n",
            "  3825    8    3  312  136    5    4   11   14 5015   39   98   26 1122\n",
            "   687    8  401  315    2   24  139   11   22  106  505    1    2    6\n",
            "     9  310  283 5173 5383   34   17  833   29 7979    5    4   11   14\n",
            "    67  114 3073  309]\n",
            " [   4  358  502    3  565    2   34    9  869 4745    2  231    3 3825\n",
            "     8    3  312  136    5    4   11   14 5015   39   98   26 1122  687\n",
            "     8  401  315    2   24  139   11   22  106  505    1    2    6    9\n",
            "   310  283 5173 5383   34   17  833   29 7979    5    4   11   14   67\n",
            "   114 3073  309    5]]\n",
            "Prview of y:\n",
            "[ 114 3073  309    5    4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Safer train/val split (avoid windowa leakage)"
      ],
      "metadata": {
        "id": "W-Lj8l1hIq9L"
      },
      "id": "W-Lj8l1hIq9L"
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_FRAC = 0.2\n",
        "split = int(len(X) * (1 - VAL_FRAC))\n",
        "gap = WIN   # leave a gap of one window\n",
        "\n",
        "X_train, y_train = X[:split-gap], y[:split-gap]\n",
        "X_val,   y_val   = X[split+gap:], y[split+gap:]\n",
        "\n",
        "print(\"Train:\", X_train.shape, y_train.shape, \" Val:\", X_val.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "qd5EK0AGIqgX",
        "outputId": "2291f18c-4e80-450c-a90a-d5afe86113a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qd5EK0AGIqgX",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (3845325, 60) (3845325,)  Val: (961287, 60) (961287,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building RNN model"
      ],
      "metadata": {
        "id": "GW03d0DIGRI4"
      },
      "id": "GW03d0DIGRI4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Define LSTM model with embedding"
      ],
      "metadata": {
        "id": "9NOEGeAgGpHl"
      },
      "id": "9NOEGeAgGpHl"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "LSTM_UNITS = 256\n",
        "EMBEDDING_DIM = 128\n",
        "VAL_DROPOUT = 0.2\n",
        "ACTIVATION = \"softmax\"\n",
        "LOSS = \"sparse_categorical_crossentropy\"\n",
        "\n",
        "# WIN = context length of your sequences (must match your X shape)\n",
        "model = Sequential([\n",
        "    Input(shape=(WIN,)),\n",
        "    Embedding(vocab_size, EMBEDDING_DIM, mask_zero=True),\n",
        "    LSTM(LSTM_UNITS, return_sequences=True),\n",
        "    Dropout(VAL_DROPOUT),\n",
        "    LSTM(LSTM_UNITS, return_sequences=True),\n",
        "    Dropout(VAL_DROPOUT),\n",
        "    LSTM(LSTM_UNITS),\n",
        "    Dense(vocab_size, activation=ACTIVATION)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4, clipnorm=1.0),\n",
        "    loss=LOSS,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "GdElwUvYGovp",
        "outputId": "242f65d5-1e34-416e-af9b-76fd595cb8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "id": "GdElwUvYGovp",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m394,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m525,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10001\u001b[0m)          │     \u001b[38;5;34m2,570,257\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10001</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570,257</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,295,249\u001b[0m (20.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,295,249</span> (20.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,295,249\u001b[0m (20.20 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,295,249</span> (20.20 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\n",
        "EPOCHS = 15\n",
        "BATCH  = 256\n",
        "MODEL_PATH = \"day75_lstm_textgen.keras\"\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-5, verbose=1),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(MODEL_PATH, monitor=\"val_loss\", save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    validation_data=(X_val, y_val),\n",
        "    shuffle=True,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"loss\"], label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
        "plt.legend(); plt.title(\"Loss\"); plt.show()\n"
      ],
      "metadata": {
        "id": "0behxPMKGOrg",
        "outputId": "a83baae7-e5c1-4eb1-8fa6-13a193178bfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0behxPMKGOrg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m   21/15021\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17:48:25\u001b[0m 4s/step - accuracy: 0.0295 - loss: 9.0414"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9pCUAul8PmRL"
      },
      "id": "9pCUAul8PmRL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}