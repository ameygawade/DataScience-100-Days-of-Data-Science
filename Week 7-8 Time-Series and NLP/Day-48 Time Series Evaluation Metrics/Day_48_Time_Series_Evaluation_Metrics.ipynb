{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c4c27a",
   "metadata": {},
   "source": [
    "# Day-48: Time Series Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202a13f",
   "metadata": {},
   "source": [
    "We've built ARIMA and Holt-Winters models, but how do we know which one is better? Today is all about becoming the judge and jury of your forecasts. We're diving into the essential Time Series Evaluation Metrics and, crucially, the only correct way to validate your models: Walk-Forward Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a51e4b",
   "metadata": {},
   "source": [
    "## Topics Covered:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652dd3f7",
   "metadata": {},
   "source": [
    "## Time Series Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988cfbb",
   "metadata": {},
   "source": [
    "In regression, we use metrics like $R^2$\n",
    " , but for forecasting, we focus on the errorâ€”the difference between the actual value $(Y_t)$ and the forecasted value $(\\^Y_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6c386",
   "metadata": {},
   "source": [
    "### 1. RMSE: Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861868e",
   "metadata": {},
   "source": [
    "RMSE is the most common metric for regression and forecasting. It measures the average magnitude of the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0cc34",
   "metadata": {},
   "source": [
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{t=1}^{n} (Y_t - \\hat{Y}_t)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658426f",
   "metadata": {},
   "source": [
    "- `Analogy`: The Speeding Ticket. RMSE is like calculating your average speeding fine. Because you square the error, large errors are penalized much more heavily than small errors. This makes RMSE sensitive to outliers.\n",
    "\n",
    "- Use Case: When large forecasting errors are disproportionately costly (e.g., predicting an inventory shortage for a critical part).\n",
    "\n",
    "- Units: It's in the same units as the target variable (e.g., if you're predicting sales in dollars, RMSE is in dollars)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8a5b4",
   "metadata": {},
   "source": [
    "### 2. MAE: Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f8c56",
   "metadata": {},
   "source": [
    "MAE measures the average magnitude of the error using absolute values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8181dbb7",
   "metadata": {},
   "source": [
    "$$\\text{MAE} = \\frac{1}{n}\\sum_{t=1}^{n} |Y_t - \\hat{Y}_t|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68178948",
   "metadata": {},
   "source": [
    "- `Analogy`: The Distance Traveled. MAE is simpler. It's the average absolute difference between your prediction and the truth. A large error counts just as much as two small errors that add up to the same amount. It is less sensitive to outliers than RMSE.\n",
    "\n",
    "- Use Case: When you want a robust, easily understandable metric of average error.\n",
    "\n",
    "- Units: It's in the same units as the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791c900",
   "metadata": {},
   "source": [
    "### 3. MAPE: Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8be50f",
   "metadata": {},
   "source": [
    "MAPE measures the average accuracy in percentage terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fc37a",
   "metadata": {},
   "source": [
    "$$\\text{MPAE} = \\frac{100}{n}\\sum_{t=1}^{n} |\\frac{Y_t - \\hat{Y}_t}{Y_t}|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd17342",
   "metadata": {},
   "source": [
    "- `Analogy`: The Relative Cost. MAPE answers the question: \"On average, how far off was my forecast as a percentage of the actual value?\" It's great for comparing performance across different time series with vastly different scales (e.g., comparing sales forecasts for a $5 item and a $5,000 item).\n",
    "\n",
    "- `Warning`: MAPE is undefined when $Y_t$ is zero and unstable when $Y_t$ is close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39105c32",
   "metadata": {},
   "source": [
    "## Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12501025",
   "metadata": {},
   "source": [
    "When validating a time series model, you CANNOT use a standard train/test split (e.g., 80% train, 20% test with random sampling). Time is sequential, and your model must only be trained on data before the forecast date.\n",
    "\n",
    "Walk-Forward Validation (also called Rolling Origin Evaluation) is the correct technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6483d6",
   "metadata": {},
   "source": [
    "### The Process:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facaad98",
   "metadata": {},
   "source": [
    "1. *Initial Split*: \n",
    "  - Define your initial training set and a small testing window (e.g., 1 month).\n",
    "\n",
    "2. *Train & Forecast*:\n",
    "  - *Step 1*: Train the model on the data up to $T_0$.\n",
    "  - *Step 2*: Forecast $T_1$. Record the error.\n",
    "\n",
    "3. *Walk Forward*:\n",
    "  - *Step 3*: Retrain the model by adding the actual data point $T_1$ to the training set.\n",
    "  - *Step 4*: Forecast $T_2$. Record the error.\n",
    "\n",
    "4. *Repeat*: The process \"walks forward\" one time step at a time, retraining the model with the latest actual data before each new forecast.\n",
    "\n",
    "5. *Analogy*: The Pilot's Logbook. A pilot doesn't just train on old flights and then guess. They fly a short leg, observe the results, update their navigation based on the actual conditions they just flew through, and then forecast the next short leg. This ensures the model is always using the most recent information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b981d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Walk-Forward Validation (Test Size: 20 periods) ---\n",
      "\n",
      "--- Evaluation Metrics (Walk-Forward) ---\n",
      "RMSE (Root Mean Squared Error): 2.058\n",
      "MAE (Mean Absolute Error): 1.747\n",
      "MAPE (Mean Absolute Percentage Error): 3.659%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "# --- 1. Recreate Time Series Data ---\n",
    "np.random.seed(42)\n",
    "index = pd.date_range(start='2020', periods=100, freq='ME')\n",
    "data = 5 * np.sin(np.linspace(0, 3*np.pi, 100)) + np.arange(100) * 0.5 + np.random.randn(100) * 2\n",
    "ts = pd.Series(data, index=index)\n",
    "\n",
    "# --- 2. Setup Walk-Forward Validation ---\n",
    "split_point = int(len(ts) * 0.8)\n",
    "train = ts[:split_point]\n",
    "test = ts[split_point:] \n",
    "\n",
    "history = [x for x in train.values]\n",
    "predictions = list()\n",
    "\n",
    "arima_order = (1, 1, 0)\n",
    "print(f\"--- Starting Walk-Forward Validation (Test Size: {len(test)} periods) ---\")\n",
    "\n",
    "# Walk through each step in the test set\n",
    "for t in range(len(test)):\n",
    "    # 1. TRAIN: Fit the model using all data in 'history'\n",
    "    model = ARIMA(history, order=arima_order)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # 2. FORECAST: Make a single-step forecast\n",
    "    yhat = model_fit.forecast(steps=1)[0]\n",
    "    predictions.append(yhat)\n",
    "\n",
    "    # 3. WALK FORWARD: Get the actual observation and add it to history\n",
    "    obs = test.values[t]\n",
    "    history.append(obs)\n",
    "    \n",
    "# Convert test and prediction lists to arrays\n",
    "actual_values = test.values\n",
    "predicted_values = np.array(predictions)\n",
    "\n",
    "# --- 4. Evaluate Metrics (Using Scikit-learn Functions) ---\n",
    "print(\"\\n--- Evaluation Metrics (Walk-Forward) ---\")\n",
    "\n",
    "# RMSE (Still requires mean_squared_error)\n",
    "rmse = np.sqrt(mean_squared_error(actual_values, predicted_values))\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.3f}\")\n",
    "\n",
    "# MAE (Using sklearn.metrics.mean_absolute_error)\n",
    "mae = mean_absolute_error(actual_values, predicted_values)\n",
    "print(f\"MAE (Mean Absolute Error): {mae:.3f}\")\n",
    "\n",
    "# MAPE (Using sklearn.metrics.mean_absolute_percentage_error)\n",
    "# Note: The sklearn function returns MAPE as a fraction (0.0 to 1.0), so we multiply by 100\n",
    "mape = mean_absolute_percentage_error(actual_values, predicted_values) * 100 \n",
    "print(f\"MAPE (Mean Absolute Percentage Error): {mape:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6b33d",
   "metadata": {},
   "source": [
    "## Summary of Day 48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4e2a14",
   "metadata": {},
   "source": [
    "\n",
    "Today, you armed yourself with the metrics to evaluate and compare models (RMSE,MAE,MAPE) and, most importantly, learned the correct validation strategy: Walk-Forward Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf7cce",
   "metadata": {},
   "source": [
    "## What's Next (Day 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed56ab",
   "metadata": {},
   "source": [
    "\n",
    "Tomorrow, on Day 49, we are putting everything together in a Comprehensive Time Series Forecasting Project! We'll use the diagnostic tools from Day 47, the models from Days 45 and 46, and the metrics and validation from today to build and select the ultimate forecasting solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1f368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
